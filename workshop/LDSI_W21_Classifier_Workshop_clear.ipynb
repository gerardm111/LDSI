{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf4257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn import model_selection\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.symbols import ORTH\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a01323",
   "metadata": {},
   "source": [
    "## Some boilerplate code for nicer looking confusion matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d16b76f",
   "metadata": {},
   "source": [
    "abridged from [scikit-learn example code](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ec052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde4cb5",
   "metadata": {},
   "source": [
    "## Some helper code to analyze TFIDF data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09239f14",
   "metadata": {},
   "source": [
    "Credit for code goes to [buhrmann.github.io](https://buhrmann.github.io/tfidf-analysis.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3df1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_tfidf_features(row, features, top_n=15):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df\n",
    "\n",
    "\n",
    "def top_features_in_doc(Xtr, features, row_id, top_n=15):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    xtr_row = Xtr[row_id]\n",
    "    if type(xtr_row) is not np.ndarray:\n",
    "        xtr_row = xtr_row.toarray()\n",
    "    row = np.squeeze(xtr_row)\n",
    "    return top_tfidf_features(row, features, top_n)\n",
    "\n",
    "\n",
    "def top_mean_features(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return the top n features that on average are most important amongst documents in rows\n",
    "        indentified by indices in grp_ids. '''\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids]\n",
    "    else:\n",
    "        D = Xtr\n",
    "    if type(D) is not np.ndarray:\n",
    "        D = D.toarray()\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_features(tfidf_means, features, top_n)\n",
    "\n",
    "\n",
    "def top_features_by_class(Xtr, y, features, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return a list of dfs, where each df holds top_n features and their mean tfidf value\n",
    "        calculated across documents with the same class label. '''\n",
    "    dfs = {}\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        ids = np.where(y==label)\n",
    "        feats_df = top_mean_features(Xtr, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n",
    "        feats_df.label = label\n",
    "        dfs[label] = feats_df\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def span_top_tfidf(spans_txt, spans_tfidf, features, index):\n",
    "    print('span text:\\n'+spans_txt[index]+'\\n')\n",
    "    print(top_features_in_doc(spans_tfidf, features, index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51593f7",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb485676",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_fpath = 'ldsi_w21_curated_annotations_v2.json'\n",
    "data = json.load(open(corpus_fpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c194b5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['documents', 'annotations', 'types'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d34af9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '61bb066d97ad59b4cfc4699a',\n",
       " 'start': 15922,\n",
       " 'end': 16078,\n",
       " 'document': '61aea57397ad59b4cfc41399',\n",
       " 'type': '61aeaf8097ad59b4cfc416d7'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4858862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'61aea55c97ad59b4cfc4128c'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['documents'][0]['_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f06be9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d96cb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', 'name', 'plainText', 'outcome'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['documents'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4600df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'61aea55c97ad59b4cfc4128c'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['documents'][0]['_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3800461",
   "metadata": {},
   "source": [
    "Define some convenience shorthands and dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e46bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = data['annotations']\n",
    "documents_by_id = {d['_id']: d for d in data['documents']}\n",
    "types_by_id = {t['_id']: t for t in data['types']}\n",
    "type_ids_by_name = {t['name']: t['_id'] for t in data['types']}\n",
    "type_names_by_id = {t['_id']: t['name'] for t in data['types']}\n",
    "doc_id_by_name = {d['name']: d['_id'] for d in data['documents']}\n",
    "doc_name_by_id = {d['_id']: d['name'] for d in data['documents']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1456a587",
   "metadata": {},
   "source": [
    "# Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c649d",
   "metadata": {},
   "source": [
    "Examine data structures so we know how to work with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d883969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '61bb066d97ad59b4cfc4699a',\n",
       " 'start': 15922,\n",
       " 'end': 16078,\n",
       " 'document': '61aea57397ad59b4cfc41399',\n",
       " 'type': '61aeaf8097ad59b4cfc416d7'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09cf7084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('61aeaf8097ad59b4cfc416d7',\n",
       " {'_id': '61aeaf8097ad59b4cfc416d7',\n",
       "  'name': 'CaseFooter',\n",
       "  'isA': '58781cf945f90f3bfc5cba7d',\n",
       "  'attributes': []})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(types_by_id.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c5164c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('61aea55c97ad59b4cfc4128c',\n",
       " {'_id': '61aea55c97ad59b4cfc4128c',\n",
       "  'name': '0601461.txt',\n",
       "  'plainText': 'Citation Nr: 0601461\\t\\r\\nDecision Date: 01/18/06    Archive Date: 01/31/06\\r\\n\\r\\nDOCKET NO.  04-17 231\\t)\\tDATE\\r\\n\\t)\\r\\n\\t)\\r\\n\\r\\nOn appeal from the\\r\\nDepartment of Veterans Affairs Regional Office in No. Little \\r\\nRock, Arkansas\\r\\n\\r\\n\\r\\nTHE ISSUE\\r\\n\\r\\nEntitlement to service connection for hepatitis C.\\r\\n\\r\\n\\r\\nREPRESENTATION\\r\\n\\r\\nAppellant represented by:\\tThe American Legion\\r\\n\\r\\n\\r\\nWITNESS AT HEARING ON APPEAL\\r\\n\\r\\nAppellant\\r\\n\\r\\n\\r\\nATTORNEY FOR THE BOARD\\r\\n\\r\\nP. Olson, Associate Counsel\\r\\n\\r\\n\\r\\nINTRODUCTION\\r\\n\\r\\nThe veteran had active military service from May 1971 to July \\r\\n1976.\\r\\n\\r\\nThis matter comes before the Board of Veterans\\' Appeals \\r\\n(Board or BVA) on appeal from a July 2003 rating decision of \\r\\nthe Department of Veterans Affairs (VA) Regional Office (RO) \\r\\nin N. Little Rock, Arkansas.\\r\\n\\r\\nIn August 2004, the veteran testified at a video conference \\r\\nhearing before the undersigned Veterans Law Judge.  A \\r\\ntranscript of that hearing is of record.\\r\\n\\r\\nIn September 2002, the veteran claimed cirrhosis of the liver \\r\\nsecondary to alcoholism and PTSD.  In his Notice of \\r\\nDisagreement received in August 2003, the veteran also stated \\r\\nthat he was claiming cirrhosis as a secondary condition to \\r\\nhis hepatitis C.  As is unclear whether the veteran wishes to \\r\\ncontinue to pursue this claim, it is referred to the RO for \\r\\nappropriate action.\\r\\n\\r\\n\\r\\nFINDING OF FACT\\r\\n\\r\\nThe only risk factor shown in the evidence is the veteran\\'s \\r\\nreceipt of inoculations during service, and a medical \\r\\nprofessional has stated this is the only risk factor the \\r\\nveteran has for developing hepatitis C.\\r\\n\\r\\n\\r\\nCONCLUSION OF LAW\\r\\n\\r\\nResolving all doubt in the veteran\\'s favor, hepatitis C was \\r\\nincurred in active service. 38 U.S.C.A. � 1110 (West 2002); \\r\\n38 C.F.R. � 3.303 (2005).\\r\\n\\r\\n\\r\\n\\r\\nREASONS AND BASES FOR FINDING AND CONCLUSION\\r\\n\\r\\nThe Veterans Claims Assistance Act of 2000 (VCAA), Pub. L. \\r\\nNo. 106-475, 114 Stat. 2096 (2000) (codified at 38 U.S.C.A. \\r\\n�� 5100, 5102-5103A, 5106, 5107, 5126 (West 2002 & Supp. \\r\\n2005)), imposes obligations on VA in terms of its duties to \\r\\nnotify and assist claimants.  The Board observes that in \\r\\nlight of the favorable outcome of this appeal, any perceived \\r\\nlack of notice or development under the VCAA should not be \\r\\nconsidered prejudicial.  \\r\\n\\r\\nThe Board has thoroughly reviewed all the evidence in the \\r\\nappellant\\'s claims folder, which includes, but is not limited \\r\\nto:  the veteran\\'s service medical records; prior rating \\r\\ndecisions; the appellant\\'s contentions including testimony \\r\\npresented at the August 2004 video conference hearing; a VA \\r\\nexamination report dated in July 2003; and VA medical records \\r\\nfor treatment from January 1998.  Although the Board has an \\r\\nobligation to provide reasons and bases supporting this \\r\\ndecision, there is no need to discuss, in detail, the \\r\\nextensive evidence submitted by the appellant or on his \\r\\nbehalf.  See Gonzales v. West, 218 F.3d 1378, 1380-81 (Fed. \\r\\nCir. 2000) (the Board must review the entire record, but does \\r\\nnot have to discuss each piece of evidence).  Rather, the \\r\\nBoard\\'s analysis below will focus specifically on what the \\r\\nevidence shows, or fails to show, on each claim.  See \\r\\nTimberlake v. Gober, 14 Vet. App. 122 (2000) (the law \\r\\nrequires only that the Board address its reasons for \\r\\nrejecting evidence favorable to the claimant).\\r\\n\\r\\nThe veteran contends that his current diagnosis of hepatitis \\r\\nC is related to service.  Specifically, the veteran indicates \\r\\nthat he believes his current diagnosis of hepatitis C is \\r\\nrelated to either being exposed to blood via a mass \\r\\ninoculation (\"air gun\"), an incident in which medicine was \\r\\ninjected into his finger with a previously-used needle, or an \\r\\nincident in which he was exposed to another\\'s blood while in \\r\\nthe shower.\\r\\n\\r\\nService connection means that the facts establish that a \\r\\nparticular injury or disease resulting in disability was \\r\\nincurred in the line of duty in the active military service \\r\\nor, if pre-existing such service, was aggravated during \\r\\nservice.  38 U.S.C.A. � 1110; 38 C.F.R. � 3.303(a).  The \\r\\nfirst question that must be addressed, therefore, is whether \\r\\nincurrence of hepatitis C is factually shown during service.  \\r\\nThe Board concludes it was not.  The service medical records \\r\\nare absent complaints, findings or diagnoses of hepatitis \\r\\nduring service.  Thus, there is no medical evidence that \\r\\nshows that the veteran suffered from hepatitis during \\r\\nservice.  \\r\\n\\r\\nAlternatively, when a chronic disease is not present during \\r\\nservice, service connection may be established under \\r\\n38 C.F.R. � 3.303(b) by evidence of continuity of \\r\\nsymptomatology.  Such evidence is lacking here.  The veteran \\r\\ntestified in August 2004 that he was diagnosed with hepatitis \\r\\nC in 1998, and the medical evidence confirms that is when the \\r\\ndiagnosis was first made.  \\r\\n\\r\\nWhen a disease is first diagnosed after service, service \\r\\nconnection can still be granted for that condition if the \\r\\nevidence shows it was incurred in service.  38 C.F.R. \\r\\n� 3.303(d).  To prevail on the issue of service connection \\r\\nthere must be medical evidence of a current disability; \\r\\nmedical evidence, or in certain circumstances, lay evidence \\r\\nof in-service occurrence or aggravation of a disease or \\r\\ninjury; and medical evidence of a nexus between an in-service \\r\\ninjury or disease and the current disability.  See Hickson v. \\r\\nWest, 12 Vet. App. 247, 253 (1999); see also Pond v. West, 12 \\r\\nVet App. 341, 346 (1999).  In this case, the appellant \\r\\nclearly has a current disability.  The remaining question, \\r\\ntherefore, is whether there is medical evidence of a \\r\\nrelationship between the current disability and military \\r\\nservice.\\r\\n\\r\\nThe Board points out that risk factors for hepatitis C \\r\\ninclude intravenous (IV) drug use, blood transfusions before \\r\\n1992, hemodialysis, intranasal cocaine, high-risk sexual \\r\\nactivity, accidental exposure while a health care worker, and \\r\\nvarious kinds of percutaneous exposure such as tattoos, body \\r\\npiercing, acupuncture with non-sterile needles, shared \\r\\ntoothbrushes or razor blades.  VBA Letter 211B (98-110) \\r\\nNovember 30, 1998.\\r\\n\\r\\nIn a January 2000 Preventive Care record, the veteran \\r\\nreported  that he had hepatitis C and answered, \"yes\" to \\r\\nthe question, \"Do any of these risk factors apply to you; \\r\\nrec\\'d blood, been on dialysis, work with blood/blood \\r\\nproducts, had many sex partners, used injected drugs, have \\r\\ntattoos, used cocaine, live a person with Hepatitis C.\"  No \\r\\nfurther details were provided.  In contrast, a prior VA \\r\\nhistory dated in June 1999 indicates \"yes\" for the presence \\r\\nof Hepatitis C, but \"no\" for any risk factors.\\r\\n\\r\\nThe veteran underwent a VA examination in July 2003.  The \\r\\nexaminer reported that the veteran denied all known risk \\r\\nfactors specifically stating, \"I just do not know how I got \\r\\nit in.\"  The examiner reported that the veteran\\'s history \\r\\nwas negative for transfusion, drug use, and other such known \\r\\nrisk factors.  \\r\\n\\r\\nThe veteran testified that he may have been exposed to \\r\\nhepatitis C during a medical procedure in which his finger \\r\\nwas sutured.  The veteran stated that he cut his finger while \\r\\nin Vietnam, and the medic asked the veteran if he minded if \\r\\nhe used painkiller that they had left over from another case.  \\r\\nWhile there is evidence that the veteran received stitches \\r\\nwhen he cut his left index finger in March 1973 (after his \\r\\ntour in Vietnam) and that his finger was infiltrated with \\r\\nlidocaine and sutured, there is no evidence corroborating his \\r\\nallegation that the needle used to administer the lidocaine \\r\\nhad been used previously to treat other individuals.  \\r\\n\\r\\nThe veteran also testified that there was an incident when he \\r\\nwas in the shower and a woman came into the shower and blood \\r\\nwent all over the shower floor.  The veteran testified that \\r\\nalthough he was wearing shower shoes, he was still exposed to \\r\\nthe blood.  However, there is no evidence corroborating his \\r\\nallegation that this incident occurred.\\r\\n\\r\\nWith respect to the veteran\\'s contention that his hepatitis C \\r\\nis related to \"air gun\" inoculations, the veteran testified \\r\\nthat while in boot camp May 1971, he went though inoculations \\r\\nwhere the drill instructor used a pneumatic inoculator on \\r\\nevery person in series.  \\r\\n\\r\\nIn an April 2003 medical report, Dr. AHM, of the \\r\\ngastroenterology department, noted no history of IV drug use, \\r\\nno tattoos, sexual exposure overseas but \"safe sex\", and \\r\\nmass inoculation using same air gun on several people.  The \\r\\nphysician stated, \"this is the only possible potential risk \\r\\nfactor for HCV that he could identify or at least that the \\r\\npatient will volunteer.\"  \\r\\nThe veteran\\'s service record indicates that he was a Marine \\r\\nCorps recruit from May to July 1971.  The record indicates \\r\\nthat the veteran received a yellow fever vaccine on July 12, \\r\\n1971.  The Board also notes that the record does not \\r\\nspecifically identify any other risk factors for hepatitis C.  \\r\\nThe Board has reviewed all the medical evidence in the \\r\\nveteran\\'s claims file.  Although he has a history of alcohol \\r\\nand marijuana use, he has consistently denied using any other \\r\\nillegal substances or using IV drugs.  The majority of these \\r\\ndenials are shown prior to his VA claim in 2002 and, in fact, \\r\\nprior to diagnosis of Hepatitis C in 1998.  This lends \\r\\nadditional credibility to his current denials of such risk \\r\\nfactors, and there is no evidence contradicting his \\r\\ntestimony.  In reviewing his occupational history in the VA \\r\\noutpatient treatment records from 1985 to the present, there \\r\\nis no indication he worked in a medical field where he would \\r\\nbe exposed to blood products.  His past surgical history has \\r\\nbeen listed as only a tonsillectomy - a procedure that would \\r\\nnot ordinarily involve a blood transfusion, and there is no \\r\\nindication that it did.  The veteran denies having any \\r\\ntattoos, and a VA outpatient treatment record dated in \\r\\nJanuary 2001 (well over a year before the veteran filed his \\r\\nclaim) indicated no history of tattoos, blood transfusions, \\r\\nor piercings.  Again, then, there is no evidence \\r\\ncontradicting the veteran\\'s denial of these risk factors.\\r\\n\\r\\nTherefore, the only risk factor, as labeled by a medical \\r\\nprofessional, is the fact that the veteran received \\r\\ninoculations during service.  According to the Veterans \\r\\nBenefits Administration, despite the lack of any scientific \\r\\nevidence to document transmission of HCV with air gun \\r\\ninjectors, it is biologically plausible.  VBA Fast Letter 04-\\r\\n13 (June 29, 2004).  This \"plausibility,\" although not even \\r\\nremotely definitive, is the only possible explanation shown \\r\\nin this veteran\\'s record for the transmission of Hepatitis C.  \\r\\nAlthough the Fast Letter also notes the source of infection \\r\\nis unknown in some cases, this appears to invoke resolution \\r\\nof reasonable doubt in the veteran\\'s favor, when the only \\r\\nrisk factor shown for this veteran are the in-service \\r\\ninoculations.  \\r\\n\\r\\nTherefore, resolving all reasonable doubt in favor of the \\r\\nveteran, the Board concludes that the veteran likely incurred \\r\\nhepatitis C while on active duty.  38 U.S.C.A. � 5107(b); 38 \\r\\nC.F.R. � 3.102.  Accordingly, service connection for \\r\\nhepatitis C is granted.\\r\\n\\r\\nORDER\\r\\n\\r\\nEntitlement to service connection for hepatitis C is granted.\\r\\n\\r\\n\\r\\n\\r\\n____________________________________________\\r\\nMichelle L. Kane\\r\\nVeterans Law Judge, Board of Veterans\\' Appeals\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n Department of Veterans Affairs\\r\\n\\r\\n\\r\\n',\n",
       "  'outcome': 'granted'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(documents_by_id.items())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86300e3",
   "metadata": {},
   "source": [
    "# Very Basic Data Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba57567",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents_by_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b496c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lengths = [len(d['plainText']) for d in documents_by_id.values()]\n",
    "plt.hist(doc_lengths, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada34f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_num_annos = [len([a for a in annotations if a['document'] == doc_id])\n",
    "                 for doc_id in documents_by_id]\n",
    "doc_num_annos = [n for n in doc_num_annos if n > 0]\n",
    "plt.hist(doc_num_annos, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb442817",
   "metadata": {},
   "source": [
    "# Create Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29062ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all sentences assuming every annotation is a sentence\n",
    "def make_span_data(documents_by_id, types_by_id, annotations):\n",
    "    span_data = []\n",
    "    for a in annotations:\n",
    "        start = a['start']\n",
    "        end = a['end']\n",
    "        document_txt = documents_by_id[a['document']]['plainText']\n",
    "        atype = a['type']\n",
    "        sd = {'txt': document_txt[start:end],\n",
    "              'document': a['document'],\n",
    "              'type': types_by_id[atype]['name'],\n",
    "              'start': a['start'],\n",
    "              'start_normalized': a['start'] / len(document_txt),\n",
    "              'end': a['end']}\n",
    "        span_data.append(sd)\n",
    "    return span_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3dc0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = make_span_data(documents_by_id, types_by_id, annotations)\n",
    "span_labels = [s['type'] for s in spans]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed5ffe6",
   "metadata": {},
   "source": [
    "Sample train and test set while stratifying across types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df90c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spans, test_spans = model_selection.train_test_split(spans,\n",
    "                                                           test_size=.2,\n",
    "                                                           random_state=42,\n",
    "                                                           stratify=span_labels)\n",
    "train_spans_txt = [s['txt'] for s in train_spans]\n",
    "test_spans_txt = [s['txt'] for s in test_spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "631e8983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12279\n",
      "3070\n"
     ]
    }
   ],
   "source": [
    "print(len(train_spans))\n",
    "print(len(test_spans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8091754a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'txt': 'Eddy v. Brown, 9 \\r\\nVet. App. 52 (1996). ',\n",
       " 'document': '61aea57097ad59b4cfc4135b',\n",
       " 'type': 'Citation',\n",
       " 'start': 6722,\n",
       " 'start_normalized': 0.6137131379530723,\n",
       " 'end': 6762}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e08e668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eddy v. Brown, 9 \\r\\nVet. App. 52 (1996). '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spans_txt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6fb1db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 12279; test: 3070\n"
     ]
    }
   ],
   "source": [
    "print(f'train: {len(train_spans)}; test: {len(test_spans)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92cec863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'txt': 'In this \\r\\ncase, there is in fact no medical opinion that conflicts with \\r\\nthe January 2007 opinion.',\n",
       " 'document': '61aea55c97ad59b4cfc412a0',\n",
       " 'type': 'EvidenceBasedOrIntermediateFinding',\n",
       " 'start': 5202,\n",
       " 'start_normalized': 0.8335202691876302,\n",
       " 'end': 5301}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(train_spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11acedd9",
   "metadata": {},
   "source": [
    "# Some Tough Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2467fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_basic_1 = 'In sum, as the preponderance of the evidence is against the Veteran\\'s claim, his appeal must be denied.'\n",
    "example_cit_1 = 'Smith v. Gober, 14 Vet. App. 227 (2000), aff\\'d 281 F.3d 1384 (Fed. Cir. 2002); Dela Cruz v. Principi, 15 Vet. App. 143 (2001); see also Quartuccio v. Principi, 16 Vet. App. 183 (2002).'\n",
    "example_rule_1 = '\"To establish a right to compensation for a present disability, a Veteran must show: \"(1) the existence of a present disability; (2) in-service incurrence or aggravation of a disease or injury; and (3) a causal relationship between the present disability and the disease or injury incurred or aggravated during service\"-the so-called \"nexus\" requirement.\"'\n",
    "example_mixed_1 = 'In Dingess v. Nicholson, 19 Vet. App. 473 (2006), the U.S. Court of Appeals for Veterans Claims held that, upon receipt of an application for a service-connection claim, 38 U.S.C.A. � 5103(a) and 38 C.F.R. � 3.159(b) require VA to provide the claimant with notice that a disability rating and an effective date for the award of benefits will be assigned if service connection is awarded. '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9467688",
   "metadata": {},
   "source": [
    "# Manual Tokenization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b940f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    dirty_tokens = re.split(' +', txt)  # split words\n",
    "    # remove all non-alphanumerics\n",
    "    clean_tokens = [re.sub(r'\\W', '', t).lower() \n",
    "                    for t in dirty_tokens]\n",
    "    if '' in clean_tokens:  # remove empty tokens\n",
    "        clean_tokens.remove('')\n",
    "    return clean_tokens\n",
    "\n",
    "\n",
    "def tokenize_spans(spans):\n",
    "    for s in spans:\n",
    "        s['tokens_manual'] = tokenize(s['txt'])\n",
    "        \n",
    "        \n",
    "def build_vocabulary(spans):\n",
    "    vocab_counts = {}\n",
    "    for sd in spans:\n",
    "        for t in tokenize(sd['txt']):\n",
    "            if t in vocab_counts:\n",
    "                vocab_counts[t] += 1\n",
    "            else:\n",
    "                vocab_counts[t] = 1\n",
    "    return vocab_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b86371",
   "metadata": {},
   "source": [
    "We can use this basic tokenizer to do some surface statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d74d0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'sum',\n",
       " 'as',\n",
       " 'the',\n",
       " 'preponderance',\n",
       " 'of',\n",
       " 'the',\n",
       " 'evidence',\n",
       " 'is',\n",
       " 'against',\n",
       " 'the',\n",
       " 'veterans',\n",
       " 'claim',\n",
       " 'his',\n",
       " 'appeal',\n",
       " 'must',\n",
       " 'be',\n",
       " 'denied']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(example_basic_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84e2ac1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_spans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mahaut/LDSI/workshop/LDSI_W21_Classifier_Workshop_clear.ipynb Cell 44'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mahaut/LDSI/workshop/LDSI_W21_Classifier_Workshop_clear.ipynb#ch0000043?line=0'>1</a>\u001b[0m tokenize_spans(train_spans)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_spans' is not defined"
     ]
    }
   ],
   "source": [
    "tokenize_spans(train_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c80e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_counts_manual = build_vocabulary(train_spans)\n",
    "unique_tokens_manual = [token for token, count in vocab_counts_manual.items() \n",
    "                        if count == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocab_counts_manual))\n",
    "print(vocab_counts_manual['veteran'])\n",
    "print(len(unique_tokens_manual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b889baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_lengths_manual = [len(s['tokens_manual']) for s in train_spans]\n",
    "plt.hist(span_lengths_manual, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a717e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = pd.DataFrame([{'token': t, 'count': c} for t, c in vocab_counts_manual.items()])\n",
    "vocab_df = vocab_df.set_index(['token'])\n",
    "vocab_df.sort_values('count', ascending=False)[:30].plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 6\n",
    "max_freq = 100\n",
    "feature_names_manual = sorted(token for token, count in vocab_counts_manual.items() \n",
    "                       if min_freq <= count <= max_freq)\n",
    "print(f'number of thresholded with {min_freq} < n < {max_freq}: {len(feature_names_manual)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98dd15e",
   "metadata": {},
   "source": [
    "# Basic TFIDF vectorization with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b650d",
   "metadata": {},
   "source": [
    "We are using sklear's [TFIDF vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer.fit) here, because it is faster than doing it all by ourselves and has useful default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae29f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5)\n",
    "vectorizer = vectorizer.fit(train_spans_txt)\n",
    "tfidf_features_skl = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_skl = vectorizer.transform(train_spans_txt).toarray()\n",
    "test_tfidf_skl = vectorizer.transform(test_spans_txt).toarray()\n",
    "train_spans_labels = np.array([s['type'] for s in train_spans])\n",
    "test_spans_labels = np.array([s['type'] for s in test_spans])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0471ed8d",
   "metadata": {},
   "source": [
    "... and we get numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_skl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe794a",
   "metadata": {},
   "source": [
    "Examine the top TFIDF values of tokens in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1246e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_top_tfidf(train_spans_txt, \n",
    "               train_tfidf_skl,\n",
    "               tfidf_features_skl,\n",
    "               random.randint(0, len(train_spans)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f749c",
   "metadata": {},
   "source": [
    "Examine features with highest average TFIDF score per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040105a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = top_features_by_class(train_tfidf_skl, \n",
    "                            train_spans_labels,\n",
    "                            tfidf_features_skl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce4952",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f9db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['Citation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653b0cc",
   "metadata": {},
   "source": [
    "## Train & Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a0bbd",
   "metadata": {},
   "source": [
    "Models:  \n",
    "[Gaussian Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)  \n",
    "[Support Vector Machine Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)  \n",
    "[Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)  \n",
    "[Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ec1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = SVC(gamma='auto')\n",
    "#clf = RandomForestClassifier(n_estimators=100, max_depth=12)\n",
    "#clf = tree.DecisionTreeClassifier(max_depth=8)\n",
    "clf_skl = GaussianNB()\n",
    "clf_skl = clf_skl.fit(train_tfidf_skl, train_spans_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TRAIN:\\n'+classification_report(train_spans_labels, \n",
    "                                       clf_skl.predict(train_tfidf_skl)))\n",
    "print('TEST:\\n'+classification_report(test_spans_labels,\n",
    "                                      clf_skl.predict(test_tfidf_skl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607aa8a6",
   "metadata": {},
   "source": [
    "# Build Feature Vector using Spacy\n",
    "More information: [Spacy](https://spacy.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527b00cc",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f28285c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic English pipeline provided by spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "12819f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_fact_1 = \"He related that he was \\\"having a reoccurrence of bronchitis [symptoms].\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea6da5b",
   "metadata": {},
   "source": [
    "More information on customizing tokenizers [at the Spacy docs](https://spacy.io/usage/linguistic-features#tokenization)  \n",
    "Note that you may not alter the text, but you can use it to suppress or force tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "041157cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.attrs import ORTH\n",
    "nlp.tokenizer.add_special_case('Vet. App.', [{ORTH: 'Vet. App.'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "acf5c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler = nlp.get_pipe(\"attribute_ruler\")\n",
    "patterns = [[{\"TEXT\": \"[\"}]]\n",
    "attrs = {\"POS\": \"PUNCT\"}\n",
    "ruler.add(patterns=patterns, attrs=attrs, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b25dcd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Dingess v. Nicholson, 19 Vet. App. 473 (2006), the U.S. Court of Appeals for Veterans Claims held that, upon receipt of an application for a service-connection claim, 38 U.S.C.A. � 5103(a) and 38 C.F.R. � 3.159(b) require VA to provide the claimant with notice that a disability rating and an effective date for the award of benefits will be assigned if service connection is awarded. \n",
      "1 sentences:\n",
      "===\n",
      "In Dingess v. Nicholson, 19 Vet. App. 473 (2006), the U.S. Court of Appeals for Veterans Claims held that, upon receipt of an application for a service-connection claim, 38 U.S.C.A. � 5103(a) and 38 C.F.R. � 3.159(b) require VA to provide the claimant with notice that a disability rating and an effective date for the award of benefits will be assigned if service connection is awarded.\n",
      "===\n",
      "In | in | ADP\n",
      "Dingess | Dingess | PROPN\n",
      "v. | v. | ADP\n",
      "Nicholson | Nicholson | PROPN\n",
      ", | , | PUNCT\n",
      "19 | 19 | NUM\n",
      "Vet. App. | Vet. App. | PROPN\n",
      "473 | 473 | NUM\n",
      "( | ( | PUNCT\n",
      "2006 | 2006 | NUM\n",
      ") | ) | PUNCT\n",
      ", | , | PUNCT\n",
      "the | the | DET\n",
      "U.S. | U.S. | PROPN\n",
      "Court | Court | PROPN\n",
      "of | of | ADP\n",
      "Appeals | Appeals | PROPN\n",
      "for | for | ADP\n",
      "Veterans | Veterans | PROPN\n",
      "Claims | Claims | PROPN\n",
      "held | hold | VERB\n",
      "that | that | SCONJ\n",
      ", | , | PUNCT\n",
      "upon | upon | SCONJ\n",
      "receipt | receipt | NOUN\n",
      "of | of | ADP\n",
      "an | an | DET\n",
      "application | application | NOUN\n",
      "for | for | ADP\n",
      "a | a | DET\n",
      "service | service | NOUN\n",
      "- | - | PUNCT\n",
      "connection | connection | NOUN\n",
      "claim | claim | NOUN\n",
      ", | , | PUNCT\n",
      "38 | 38 | NUM\n",
      "U.S.C.A. | U.S.C.A. | PROPN\n",
      "� | � | PROPN\n",
      "5103(a | 5103(a | NUM\n",
      ") | ) | PUNCT\n",
      "and | and | CCONJ\n",
      "38 | 38 | NUM\n",
      "C.F.R. | C.F.R. | PROPN\n",
      "� | � | PROPN\n",
      "3.159(b | 3.159(b | PROPN\n",
      ") | ) | PUNCT\n",
      "require | require | VERB\n",
      "VA | VA | PROPN\n",
      "to | to | PART\n",
      "provide | provide | VERB\n",
      "the | the | DET\n",
      "claimant | claimant | NOUN\n",
      "with | with | ADP\n",
      "notice | notice | NOUN\n",
      "that | that | SCONJ\n",
      "a | a | DET\n",
      "disability | disability | NOUN\n",
      "rating | rating | NOUN\n",
      "and | and | CCONJ\n",
      "an | an | DET\n",
      "effective | effective | ADJ\n",
      "date | date | NOUN\n",
      "for | for | ADP\n",
      "the | the | DET\n",
      "award | award | NOUN\n",
      "of | of | ADP\n",
      "benefits | benefit | NOUN\n",
      "will | will | AUX\n",
      "be | be | AUX\n",
      "assigned | assign | VERB\n",
      "if | if | SCONJ\n",
      "service | service | NOUN\n",
      "connection | connection | NOUN\n",
      "is | be | AUX\n",
      "awarded | award | VERB\n",
      ". | . | PUNCT\n"
     ]
    }
   ],
   "source": [
    "#test_txt = example_basic_1\n",
    "#test_txt = example_cit_1\n",
    "#test_txt = example_fact_1\n",
    "test_txt = example_mixed_1\n",
    "#test_txt = 'today (not tomorrow) is a big day'\n",
    "print(test_txt)\n",
    "doc = nlp(test_txt)\n",
    "print(f'{len(list(doc.sents))} sentences:')\n",
    "print('===')\n",
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "print('===')\n",
    "for t in doc:\n",
    "    print(f'{t.text} | {t.lemma_} | {t.pos_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eb85ae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenize(txt):\n",
    "    doc = nlp(txt)\n",
    "    tokens = list(doc)\n",
    "    clean_tokens = []\n",
    "    par_removed = ''\n",
    "    for t in tokens:\n",
    "        if t.pos_ == 'PUNCT':\n",
    "            pass\n",
    "        elif t.pos_ == 'NUM':\n",
    "            clean_tokens.append(f'<NUM{len(t)}>')\n",
    "        elif t.lemma_ == \"'s\":\n",
    "            pass\n",
    "        elif t.lemma_ == \"'\" or t.lemma_ == \"\\n\" or t.lemma_ == \"\\r\" or t.lemma_ == \"\\t\":\n",
    "            pass\n",
    "        elif '(' in t.lemma_:\n",
    "            par_split = t.lemma_.split('(')\n",
    "            for elem in par_split:\n",
    "                par_removed = par_removed + elem\n",
    "            par_split = spacy_tokenize(par_removed)\n",
    "            for elem in par_split:\n",
    "                clean_tokens.append(elem)\n",
    "        elif \"\\n\" in t.lemma_:\n",
    "            par_split = t.lemma_.split('\\n')\n",
    "            for elem in par_split:\n",
    "                if elem != ' ' and elem != '':\n",
    "                    par_removed = par_removed + ' ' + elem\n",
    "            par_split = spacy_tokenize(par_removed)\n",
    "            for elem in par_split:\n",
    "                clean_tokens.append(elem)\n",
    "        else:\n",
    "            clean_tokens.append(t.lemma_.lower())\n",
    "    return clean_tokens\n",
    "\n",
    "def spans_add_spacy_tokens(spans):\n",
    "    for s in spans:\n",
    "        s['tokens_spacy'] = spacy_tokenize(s['txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9d367397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize(example_cit_1)\n",
    "example_seg_1 = \"Acting Veterans Law Judge, Board of Veterans' Appeals\\n\\nUnder 38 U.S.C.A. \\u00a7 7252, only \\ntoday a decision of the Board is appealable to the Court.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d96fc102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acting Veterans Law Judge, Board of Veterans' Appeals\n",
      "\n",
      "Under 38 U.S.C.A. § 7252, only \n",
      "today a decision of the Board is appealable to the Court.\n",
      "['acting', 'veterans', 'law', 'judge', 'board', 'of', 'veterans', 'appeal', 'under', '<NUM2>', 'u.s.c.a.', '§', '<NUM4>', 'only', 'today', 'a', 'decision', 'of', 'the', 'board', 'be', 'appealable', 'to', 'the', 'court'] 25\n"
     ]
    }
   ],
   "source": [
    "text = example_seg_1\n",
    "print(text)\n",
    "print(spacy_tokenize(text), len(spacy_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d7fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will take a moment\n",
    "spans_add_spacy_tokens(train_spans)\n",
    "spans_add_spacy_tokens(test_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2298137",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice(train_spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0091754",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87eec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suboptimal: tokenizer gets called twice\n",
    "spacy_tfidf_vectorizer = TfidfVectorizer(tokenizer=spacy_tokenize,\n",
    "                                         min_df=3,\n",
    "                                         ngram_range=(1,1))\n",
    "spacy_tfidf_vectorizer = spacy_tfidf_vectorizer.fit(train_spans_txt)\n",
    "tfidf_features_spacy = spacy_tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498d032d",
   "metadata": {},
   "source": [
    "### Small walkthrough of how to extend/compose feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f06f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy feature vector extension\n",
    "train_tfidf_spacy = spacy_tfidf_vectorizer.transform(train_spans_txt).toarray()\n",
    "print(train_tfidf_spacy.shape)\n",
    "train_starts_normalized = np.array([s['start_normalized'] for s in train_spans])\n",
    "print(train_starts_normalized.shape)\n",
    "print(np.expand_dims(train_starts_normalized, axis=1).shape)\n",
    "ext = np.concatenate((train_tfidf_spacy, \n",
    "                      np.expand_dims(train_starts_normalized, axis=1)), axis=1)\n",
    "print(ext.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01528477",
   "metadata": {},
   "source": [
    "### Examine highest average TFIDF features by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = top_features_by_class(train_tfidf_spacy, train_spans_labels, tfidf_features_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['Citation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a34b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vectors_and_labels(spans, vectorizer):\n",
    "    # function takes long to execute\n",
    "    # note: we un-sparse the matrix here to be able to manipulate it\n",
    "    tfidf = spacy_tfidf_vectorizer.transform([s['txt'] for s in spans]).toarray()\n",
    "    starts_normalized = np.array([s['start_normalized'] for s in spans])\n",
    "    num_tokens = np.array([len(s['tokens_spacy']) for s in spans])\n",
    "    y = np.array([s['type'] for s in spans])\n",
    "    X = np.concatenate((tfidf, np.expand_dims(starts_normalized, axis=1)), axis=1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17317ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = make_feature_vectors_and_labels(train_spans, spacy_tfidf_vectorizer)\n",
    "test_X, test_y = make_feature_vectors_and_labels(test_spans, spacy_tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{train_X.shape} {train_y.shape}')\n",
    "print(f'{test_X.shape} {test_y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9776e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = GaussianNB()\n",
    "clf = tree.DecisionTreeClassifier(max_depth=12)\n",
    "clf = clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60868d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('TEST:\\n'+classification_report(test_spans_labels, clf.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f77969",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_spans_labels, clf.predict(test_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_names_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63160b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_errors(clf, eval_spans, vectorizer, \n",
    "                      select_true_label=None, \n",
    "                      select_pred_label=None):\n",
    "    eval_X, eval_y = make_feature_vectors_and_labels(eval_spans, vectorizer)\n",
    "    eval_spans_txt = [s['txt'] for s in eval_spans]\n",
    "    eval_spans_labels = [s['type'] for s in eval_spans]\n",
    "    pred_y = clf.predict(eval_X)\n",
    "    for i in range(len(eval_spans)):\n",
    "        true_label = eval_spans_labels[i]\n",
    "        pred_label = pred_y[i]\n",
    "        if true_label != pred_label:\n",
    "            if select_true_label and true_label != select_true_label: continue\n",
    "            if select_pred_label and pred_label != select_pred_label: continue\n",
    "            doc_name = documents_by_id[eval_spans[i]['document']]['name']\n",
    "            print('sentence # '+str(i)+' / case '+doc_name+' / @'+str(eval_spans[i]['start']))\n",
    "            print('pred: '+pred_label+' / true: '+true_label)\n",
    "            print(eval_spans[i]['txt'])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5607c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_errors(clf,\n",
    "                  random.sample(train_spans, 100),\n",
    "                  spacy_tfidf_vectorizer,\n",
    "                  select_pred_label='Evidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a537f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
